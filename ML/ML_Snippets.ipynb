{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning Algorithms\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df_model = df_model_saved[['label'] + features_base]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(df_model)\n",
    "df_model_norm = pd.DataFrame(np_scaled, columns=['label'] + features_base)\n",
    "\n",
    "df_model_norm['label'] = df_model_norm['label'].map(lambda x: 1 if x else -1)\n",
    "train, validation = train_test_split(df_model_norm, test_size=0.2)\n",
    "validation.reset_index(inplace=True)\n",
    "\n",
    "model = LogisticRegressionCV(\n",
    "    Cs=list(np.power(10.0, np.arange(-10, 10))), \n",
    "    penalty='l2', # 'l1', 'l2' \n",
    "    scoring='roc_auc',  # 'accuracy', 'roc_auc', 'neg_log_loss'\n",
    "    cv=5, \n",
    "    random_state=777, \n",
    "    max_iter=10000, \n",
    "    fit_intercept=True, \n",
    "    solver='newton-cg',  # 'newton-cg', ‘lbfgs’, ‘sag’; ‘liblinear’\n",
    "    tol=10\n",
    ")\n",
    "model_fit = model.fit(train[features_base], train['label'])\n",
    "feature_importance = np.std(train[features_base], 0) * model_fit.coef_[0]\n",
    "\n",
    "# The first column is the probability that the entry has the -1 label \n",
    "# and the second column is the probability that the entry has the +1 label.\n",
    "prediction = pd.DataFrame(model_fit.predict_proba(validation[features_base]), columns=['NotCompleted', 'Completed'])\n",
    "print('For all market, accuracy %.3f'%(model_fit.score(validation[features_base], validation['label'])))\n",
    "\n",
    "df_check = validation[['label']].join(prediction)\n",
    "\n",
    "i_m, F1 = 0, 0\n",
    "precision, recall = 0, 0\n",
    "for i in [j / 30 for j in range(1,21)]:\n",
    "    Y_true = df_check['label']\n",
    "    Y_predict = df_check['Completed'].map(lambda x: 1 if x > i else -1)\n",
    "    f = metrics.f1_score(Y_true, Y_predict)\n",
    "    p = metrics.precision_score(Y_true, Y_predict)\n",
    "    r = metrics.recall_score(Y_true, Y_predict)\n",
    "    if f > F1:\n",
    "        i_m, F1 = i, f\n",
    "        precision, recall = p, r\n",
    "print('Maximum F1 score is %.3f at %.3f with precision %.3f and recall %.3f.'%(F1, i_m, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "df_model = df_model_saved[['label'] + features_base]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(df_model)\n",
    "df_model_norm = pd.DataFrame(np_scaled, columns=['label'] + features_base)\n",
    "\n",
    "df_model_norm['label'] = df_model_norm['label'].map(lambda x: 1 if x else -1)\n",
    "train, validation = train_test_split(df_model_norm, test_size=0.2)\n",
    "validation.reset_index(inplace=True)\n",
    "\n",
    "model = RandomForestClassifier(n_jobs=-1)\n",
    "parameters = {\n",
    "    \"n_estimators\" : [20, 50, 100, 200, 300],\n",
    "    \"max_depth\" : [4, 8, 16, 24, 32],\n",
    "    \"min_samples_leaf\" : [1, 2, 4, 8, 16],\n",
    "    \"max_features\":['sqrt', 'auto'],\n",
    "    \"criterion\":['gini', 'entropy'],\n",
    "    \"bootstrap\": [True, False]\n",
    "     }\n",
    "model_cv = GridSearchCV(estimator=model, param_grid=parameters, cv= 8)\n",
    "model_cv.fit(train[features_base], train['label'])\n",
    "print(model_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Regression And Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# What model to use\n",
    "flag = 'xgb'\n",
    "\n",
    "# Get train, test and predict DataFrame\n",
    "train_data = sales[features_cols]\n",
    "train_label = sales['log_diff']\n",
    "\n",
    "train_data, test_data, train_label, test_label = train_test_split(train_data, train_label, \n",
    "                                                                test_size=0.05, random_state=42)\n",
    "\n",
    "predict_data = sales[sales.fscl_mn_id == time_filter][features_cols]\n",
    "predict_label = sales[sales.fscl_mn_id == time_filter]['log_diff']\n",
    "\n",
    "# Grid search and cross validation\n",
    "if flag == 'xgb':\n",
    "    xgb = XGBRegressor(n_jobs=-1, silent=1, subsample=0.8, eval_metric='rmse')\n",
    "    params = {\n",
    "        \"max_depth\" : [3, 4, 5, 6, 7, 8],\n",
    "        \"n_estimators\": [20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 240, 280, 320, 400],\n",
    "        \"min_child_weight\": [1, 3, 5],\n",
    "        \"gamma\": [i/10.0 for i in range(3,6)],\n",
    "        \"colsample_bytree\": [i/10.0 for i in range(6,11)]\n",
    "         }\n",
    "    grid = GridSearchCV(estimator=xgb, param_grid=params, cv=8)\n",
    "elif flag == 'rf':\n",
    "    rf = RandomForestRegressor(n_jobs=-1)\n",
    "    params = {\n",
    "    \"n_estimators\" : [20, 40, 60, 80, 100, 120, 140, 160, 180, 200],\n",
    "    \"max_depth\" : [4, 6, 8, 10, 12],\n",
    "    \"min_samples_leaf\" : [1, 2, 4, 8, 10, 12],\n",
    "    \"criterion\":['mse', 'mae']\n",
    "     }\n",
    "    grid = GridSearchCV(estimator=rf, param_grid=params, cv=8)\n",
    "\n",
    "grid.fit(train_data, train_label)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "# Get prediction\n",
    "ypred = grid.best_estimator_.predict(predict_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
